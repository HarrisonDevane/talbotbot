Updates from v4:
- Will use more input channels (4 previous half moves = 4x12) + 2 for three move repitition counters.
- Will train on more diverse data -> 
    20 GM moves (30+ moves per game), 
    5M lichess (2600+, 30+ moves per game), 
    2M tactics,
    2M endgame (random subset of 3-7 piece positions). To generate previous board states, play 4 moves in given position.
    0.01s -> 0.02s per position SF eval
- Added new utils function for board state - flip input board state to current player, should make for better generalization.
- Added dropout
    After 10 layers (out of 20), start using 10% dropout on hidden convolutional layers
    25% dropout on fully connected value head layer
- Switch optimizer to AdamW which should make for better regularization